{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ea4c3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error  # 루트 제곱 평균 오차\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.preprocessing import StandardScaler  # 평균 0, 표준편차 1\n",
    "from sklearn.preprocessing import MinMaxScaler  # 백분위\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ea563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# dir(sklearn.naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f6b96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8128, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_url = (\n",
    "    \"https://media.githubusercontent.com/media/musthave-ML10/data_source/main/car.csv\"\n",
    ")\n",
    "data = pd.read_csv(file_url)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c410e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498 CC</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner     mileage   engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248 CC      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498 CC  103.52 bhp   \n",
       "\n",
       "                torque  seats  \n",
       "0       190Nm@ 2000rpm    5.0  \n",
       "1  250Nm@ 1500-2500rpm    5.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec14404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   name           8128 non-null   object \n",
      " 1   year           8128 non-null   int64  \n",
      " 2   selling_price  8128 non-null   int64  \n",
      " 3   km_driven      8128 non-null   int64  \n",
      " 4   fuel           8128 non-null   object \n",
      " 5   seller_type    8128 non-null   object \n",
      " 6   transmission   8128 non-null   object \n",
      " 7   owner          8128 non-null   object \n",
      " 8   mileage        7907 non-null   object \n",
      " 9   engine         7907 non-null   object \n",
      " 10  max_power      7913 non-null   object \n",
      " 11  torque         7906 non-null   object \n",
      " 12  seats          7907 non-null   float64\n",
      "dtypes: float64(1), int64(3), object(9)\n",
      "memory usage: 825.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e01b66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8128</td>\n",
       "      <td>8128.000000</td>\n",
       "      <td>8.128000e+03</td>\n",
       "      <td>8.128000e+03</td>\n",
       "      <td>8128</td>\n",
       "      <td>8128</td>\n",
       "      <td>8128</td>\n",
       "      <td>8128</td>\n",
       "      <td>7907</td>\n",
       "      <td>7907</td>\n",
       "      <td>7913</td>\n",
       "      <td>7906</td>\n",
       "      <td>7907.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>393</td>\n",
       "      <td>121</td>\n",
       "      <td>322</td>\n",
       "      <td>441</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>18.9 kmpl</td>\n",
       "      <td>1248 CC</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4402</td>\n",
       "      <td>6766</td>\n",
       "      <td>7078</td>\n",
       "      <td>5289</td>\n",
       "      <td>225</td>\n",
       "      <td>1017</td>\n",
       "      <td>377</td>\n",
       "      <td>530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.804011</td>\n",
       "      <td>6.382718e+05</td>\n",
       "      <td>6.981951e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.416719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.044249</td>\n",
       "      <td>8.062534e+05</td>\n",
       "      <td>5.655055e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1983.000000</td>\n",
       "      <td>2.999900e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>2.549990e+05</td>\n",
       "      <td>3.500000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.750000e+05</td>\n",
       "      <td>9.800000e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>2.360457e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name         year  selling_price     km_driven  \\\n",
       "count                     8128  8128.000000   8.128000e+03  8.128000e+03   \n",
       "unique                    2058          NaN            NaN           NaN   \n",
       "top     Maruti Swift Dzire VDI          NaN            NaN           NaN   \n",
       "freq                       129          NaN            NaN           NaN   \n",
       "mean                       NaN  2013.804011   6.382718e+05  6.981951e+04   \n",
       "std                        NaN     4.044249   8.062534e+05  5.655055e+04   \n",
       "min                        NaN  1983.000000   2.999900e+04  1.000000e+00   \n",
       "25%                        NaN  2011.000000   2.549990e+05  3.500000e+04   \n",
       "50%                        NaN  2015.000000   4.500000e+05  6.000000e+04   \n",
       "75%                        NaN  2017.000000   6.750000e+05  9.800000e+04   \n",
       "max                        NaN  2020.000000   1.000000e+07  2.360457e+06   \n",
       "\n",
       "          fuel seller_type transmission        owner    mileage   engine  \\\n",
       "count     8128        8128         8128         8128       7907     7907   \n",
       "unique       4           3            2            5        393      121   \n",
       "top     Diesel  Individual       Manual  First Owner  18.9 kmpl  1248 CC   \n",
       "freq      4402        6766         7078         5289        225     1017   \n",
       "mean       NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "std        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "min        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "25%        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "50%        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "75%        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "max        NaN         NaN          NaN          NaN        NaN      NaN   \n",
       "\n",
       "       max_power          torque        seats  \n",
       "count       7913            7906  7907.000000  \n",
       "unique       322             441          NaN  \n",
       "top       74 bhp  190Nm@ 2000rpm          NaN  \n",
       "freq         377             530          NaN  \n",
       "mean         NaN             NaN     5.416719  \n",
       "std          NaN             NaN     0.959588  \n",
       "min          NaN             NaN     2.000000  \n",
       "25%          NaN             NaN     5.000000  \n",
       "50%          NaN             NaN     5.000000  \n",
       "75%          NaN             NaN     5.000000  \n",
       "max          NaN             NaN    14.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f480da9",
   "metadata": {},
   "source": [
    "# 전처리 : 텍스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a080f9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1248</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1498</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1497</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1298</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>1197</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>1493</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>1248</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>1396</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>1396</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1\n",
       "0     1248  CC\n",
       "1     1498  CC\n",
       "2     1497  CC\n",
       "3     1396  CC\n",
       "4     1298  CC\n",
       "...    ...  ..\n",
       "8123  1197  CC\n",
       "8124  1493  CC\n",
       "8125  1248  CC\n",
       "8126  1396  CC\n",
       "8127  1396  CC\n",
       "\n",
       "[8128 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data[\"engine\"].str.replace(\"CC\", \"\").str.replace(\" \", \"\")[0]\n",
    "# data[\"engine\"].str.replace(\" CC\", \"\")[0]\n",
    "data[\"engine\"].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1745af1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>engine_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248</td>\n",
       "      <td>74 bhp</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498</td>\n",
       "      <td>103.52 bhp</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner     mileage engine   max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl   1248      74 bhp   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl   1498  103.52 bhp   \n",
       "\n",
       "                torque  seats engine_unit  \n",
       "0       190Nm@ 2000rpm    5.0          CC  \n",
       "1  250Nm@ 1500-2500rpm    5.0          CC  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"engine\", \"engine_unit\"]] = data[\"engine\"].str.split(expand=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b06bbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"engine\"] = data[\"engine\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "869ee8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"engine\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f0a46b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CC', nan], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"engine_unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61bd85d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(221)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"engine\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cef990a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"engine_unit\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a78a044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>max_power_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4 kmpl</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14 kmpl</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.52</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bhp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner     mileage  engine max_power  \\\n",
       "0  Individual       Manual   First Owner   23.4 kmpl  1248.0        74   \n",
       "1  Individual       Manual  Second Owner  21.14 kmpl  1498.0    103.52   \n",
       "\n",
       "                torque  seats max_power_unit  \n",
       "0       190Nm@ 2000rpm    5.0            bhp  \n",
       "1  250Nm@ 1500-2500rpm    5.0            bhp  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"max_power\", \"max_power_unit\"]] = data[\"max_power\"].str.split(expand=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f66baa3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'bhp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mmax_power\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_power\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfloat32\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'bhp'"
     ]
    }
   ],
   "source": [
    "data[\"max_power\"] = data[\"max_power\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1508af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>max_power_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>Maruti Omni CNG</td>\n",
       "      <td>2000</td>\n",
       "      <td>80000</td>\n",
       "      <td>100000</td>\n",
       "      <td>CNG</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>10.9 km/kg</td>\n",
       "      <td>796.0</td>\n",
       "      <td>bhp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  year  selling_price  km_driven fuel seller_type  \\\n",
       "4933  Maruti Omni CNG  2000          80000     100000  CNG  Individual   \n",
       "\n",
       "     transmission         owner     mileage  engine max_power torque  seats  \\\n",
       "4933       Manual  Second Owner  10.9 km/kg   796.0       bhp    NaN    8.0   \n",
       "\n",
       "     max_power_unit  \n",
       "4933           None  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"max_power\"] == \"bhp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "877f9ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pd.NA)\n",
    "import numpy as np\n",
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "47491885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def isFloat(value):\n",
    "  try:\n",
    "    #정상일때실행\n",
    "    float(value)\n",
    "    return float(value)\n",
    "  except ValueError:\n",
    "    #에러일때실행\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "797e017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"max_power\"] = data[\"max_power\"].apply(isFloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0edb8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"max_power\"] = data[\"max_power\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78ab2ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bhp', nan, None], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"max_power_unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8acb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"max_power_unit\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea83a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>mileage_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maruti Swift Dzire VDI</td>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>23.4</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>190Nm@ 2000rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>kmpl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skoda Rapid 1.5 TDI Ambition</td>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Second Owner</td>\n",
       "      <td>21.14</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.519997</td>\n",
       "      <td>250Nm@ 1500-2500rpm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>kmpl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name  year  selling_price  km_driven    fuel  \\\n",
       "0        Maruti Swift Dzire VDI  2014         450000     145500  Diesel   \n",
       "1  Skoda Rapid 1.5 TDI Ambition  2014         370000     120000  Diesel   \n",
       "\n",
       "  seller_type transmission         owner mileage  engine   max_power  \\\n",
       "0  Individual       Manual   First Owner    23.4  1248.0   74.000000   \n",
       "1  Individual       Manual  Second Owner   21.14  1498.0  103.519997   \n",
       "\n",
       "                torque  seats mileage_unit  \n",
       "0       190Nm@ 2000rpm    5.0         kmpl  \n",
       "1  250Nm@ 1500-2500rpm    5.0         kmpl  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[\"mileage\", \"mileage_unit\"]] = data[\"mileage\"].str.split(expand=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "105cdbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mileage\"] = data[\"mileage\"].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "587f4bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kmpl', 'km/kg', nan], dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"mileage_unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "121a0272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Diesel', 'Petrol', 'LPG', 'CNG'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"fuel\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0fed0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mile(x):\n",
    "  if x[\"fuel\"] == \"Patrol\":\n",
    "    return x[\"mileage\"] / 80.43\n",
    "  elif x[\"fuel\"] == \"Diesel\":\n",
    "    return x[\"mileage\"] / 73.56\n",
    "  elif x[\"fuel\"] == \"LPG\":\n",
    "    return x[\"mileage\"] / 40.85\n",
    "  else:\n",
    "    return x[\"mileage\"] / 44.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77d84b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"mileage\"] = data.apply(mile, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91be57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"mileage_unit\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7d69e022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              190Nm@ 2000rpm\n",
       "1         250Nm@ 1500-2500rpm\n",
       "2       12.7@ 2,700(kgm@ rpm)\n",
       "3    22.4 kgm at 1750-2750rpm\n",
       "4       11.5@ 4,500(kgm@ rpm)\n",
       "Name: torque, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c41808b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque\"] = data[\"torque\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "022f408e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              190NM@ 2000RPM\n",
       "1         250NM@ 1500-2500RPM\n",
       "2       12.7@ 2,700(KGM@ RPM)\n",
       "3    22.4 KGM AT 1750-2750RPM\n",
       "4       11.5@ 4,500(KGM@ RPM)\n",
       "Name: torque, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6912f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"KGM\" in data[\"torque\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afd9533b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torque_unit(x):\n",
    "  if \"NM\" in str(x):\n",
    "    return \"Nm\"\n",
    "  elif \"KGM\" in str(x):\n",
    "    return \"Kgm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b88afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque_unit\"] = data[\"torque\"].apply(torque_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b2201339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nm', 'Kgm', None], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque_unit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1d8d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              190NM@ 2000RPM\n",
       "1         250NM@ 1500-2500RPM\n",
       "2       12.7@ 2,700(KGM@ RPM)\n",
       "3    22.4 KGM AT 1750-2750RPM\n",
       "4       11.5@ 4,500(KGM@ RPM)\n",
       "Name: torque, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1ba759e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '250@ 1250-5000RPM', '510@ 1600-2400', '110(11.2)@ 4800',\n",
       "       '210 / 1900'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"torque_unit\"].isna()][\"torque\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "028bd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque_unit\"].fillna(\"Nm\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed3448ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"torque_unit\"].isna()][\"torque\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "31af83b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              190NM@ 2000RPM\n",
       "1         250NM@ 1500-2500RPM\n",
       "2       12.7@ 2,700(KGM@ RPM)\n",
       "3    22.4 KGM AT 1750-2750RPM\n",
       "4       11.5@ 4,500(KGM@ RPM)\n",
       "Name: torque, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3621301",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_str = \"12.7@ 2,700(KGM@ RPM)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc23ca62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for idx, val in enumerate(tmp_str):\n",
    "  if val not in \"0123456789.\":\n",
    "    cut = idx\n",
    "    print(cut)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b56f6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_num(x):\n",
    "  x_ = str(x)\n",
    "  for idx, val in enumerate(x_):\n",
    "    if val not in \"0123456789.\":\n",
    "      cut = idx\n",
    "      break\n",
    "  return x_[:cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "199e9991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.7'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_num(tmp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0c1c4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque\"] = data[\"torque\"].apply(split_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9df57b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         190\n",
       "1         250\n",
       "2        12.7\n",
       "3        22.4\n",
       "4        11.5\n",
       "        ...  \n",
       "8123    113.7\n",
       "8124       24\n",
       "8125      190\n",
       "8126      140\n",
       "8127      140\n",
       "Name: torque, Length: 8128, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8fc1115e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dat[\u001b[33m\"\u001b[39m\u001b[33mtorque\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorque\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfloat64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Data-A/ML-Basic/.venv/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "dat[\"torque\"] = data[\"torque\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f801100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque\"] = data[\"torque\"].replace(\"\", np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "86ed4f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque\"] = data[\"torque\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af3a1cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torque_unit\n",
       "Nm     7624\n",
       "Kgm     504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"torque_unit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25368066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torque_trans(x):\n",
    "  if x[\"torque_unit\"] == \"Kgm\":\n",
    "    return x[\"torque\"] * 9.8066\n",
    "  else:\n",
    "    return x[\"torque\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1f8c949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(190.0)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torque_trans(data.loc[0, [\"torque\", \"torque_unit\"]])\n",
    "# data.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a312f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"torque\"] = data.apply(torque_trans, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6b07a88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>fuel</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>transmission</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>torque_unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>Tata Indigo CR4</td>\n",
       "      <td>2013</td>\n",
       "      <td>290000</td>\n",
       "      <td>25000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>0.320419</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>Tata Indigo CR4</td>\n",
       "      <td>2013</td>\n",
       "      <td>290000</td>\n",
       "      <td>25000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Individual</td>\n",
       "      <td>Manual</td>\n",
       "      <td>First Owner</td>\n",
       "      <td>0.320419</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  year  selling_price  km_driven    fuel seller_type  \\\n",
       "8126  Tata Indigo CR4  2013         290000      25000  Diesel  Individual   \n",
       "8127  Tata Indigo CR4  2013         290000      25000  Diesel  Individual   \n",
       "\n",
       "     transmission        owner   mileage  engine  max_power  torque  seats  \\\n",
       "8126       Manual  First Owner  0.320419  1396.0       70.0   140.0    5.0   \n",
       "8127       Manual  First Owner  0.320419  1396.0       70.0   140.0    5.0   \n",
       "\n",
       "     torque_unit  \n",
       "8126          Nm  \n",
       "8127          Nm  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b47ca359",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"torque_unit\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6cb8c24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Maruti Swift Dzire VDI                             129\n",
       "Maruti Alto 800 LXI                                 82\n",
       "Maruti Alto LXi                                     71\n",
       "BMW X4 M Sport X xDrive20d                          62\n",
       "Maruti Swift VDI                                    61\n",
       "                                                  ... \n",
       "Skoda Fabia 1.4 TDI Ambiente                         1\n",
       "Mahindra Scorpio VLX 2WD AT BSIII                    1\n",
       "Renault KWID Climber 1.0 AMT                         1\n",
       "Mahindra XUV300 W8 Option Dual Tone Diesel BSIV      1\n",
       "Toyota Innova 2.5 GX (Diesel) 8 Seater BS IV         1\n",
       "Name: count, Length: 2058, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "03be0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"name\"] = data[\"name\"].replace(\"Land\", \"Land Rover\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a8af0",
   "metadata": {},
   "source": [
    "# 전처리 : 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f740abf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name             0.000000\n",
       "year             0.000000\n",
       "selling_price    0.000000\n",
       "km_driven        0.000000\n",
       "fuel             0.000000\n",
       "seller_type      0.000000\n",
       "transmission     0.000000\n",
       "owner            0.000000\n",
       "mileage          2.718996\n",
       "engine           2.718996\n",
       "max_power        2.657480\n",
       "torque           2.731299\n",
       "seats            2.718996\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f6be267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a9018475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7906"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d30115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7906 entries, 0 to 8127\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   name           7906 non-null   object \n",
      " 1   year           7906 non-null   int64  \n",
      " 2   selling_price  7906 non-null   int64  \n",
      " 3   km_driven      7906 non-null   int64  \n",
      " 4   fuel           7906 non-null   object \n",
      " 5   seller_type    7906 non-null   object \n",
      " 6   transmission   7906 non-null   object \n",
      " 7   owner          7906 non-null   object \n",
      " 8   mileage        7906 non-null   float64\n",
      " 9   engine         7906 non-null   float32\n",
      " 10  max_power      7906 non-null   float32\n",
      " 11  torque         7906 non-null   float64\n",
      " 12  seats          7906 non-null   float64\n",
      "dtypes: float32(2), float64(3), int64(3), object(5)\n",
      "memory usage: 803.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "105fb8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', 'fuel', 'seller_type', 'transmission', 'owner']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_list = []\n",
    "for i in data.columns:\n",
    "    if data[i].dtype == \"object\":\n",
    "        obj_list.append(i)\n",
    "obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ae4ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=obj_list, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5abd8a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>name_Ambassador Classic 2000 DSZ AC PS</th>\n",
       "      <th>name_Ambassador Grand 1500 DSZ BSIII</th>\n",
       "      <th>...</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>fuel_Petrol</th>\n",
       "      <th>seller_type_Individual</th>\n",
       "      <th>seller_type_Trustmark Dealer</th>\n",
       "      <th>transmission_Manual</th>\n",
       "      <th>owner_Fourth &amp; Above Owner</th>\n",
       "      <th>owner_Second Owner</th>\n",
       "      <th>owner_Test Drive Car</th>\n",
       "      <th>owner_Third Owner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>450000</td>\n",
       "      <td>145500</td>\n",
       "      <td>0.318108</td>\n",
       "      <td>1248.0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>190.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>370000</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.287384</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>103.519997</td>\n",
       "      <td>250.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006</td>\n",
       "      <td>158000</td>\n",
       "      <td>140000</td>\n",
       "      <td>0.400181</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>124.54382</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>225000</td>\n",
       "      <td>127000</td>\n",
       "      <td>0.312670</td>\n",
       "      <td>1396.0</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>219.66784</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007</td>\n",
       "      <td>130000</td>\n",
       "      <td>120000</td>\n",
       "      <td>0.364006</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>88.199997</td>\n",
       "      <td>112.77590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1999 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  selling_price  km_driven   mileage  engine   max_power     torque  \\\n",
       "0  2014         450000     145500  0.318108  1248.0   74.000000  190.00000   \n",
       "1  2014         370000     120000  0.287384  1498.0  103.519997  250.00000   \n",
       "2  2006         158000     140000  0.400181  1497.0   78.000000  124.54382   \n",
       "3  2010         225000     127000  0.312670  1396.0   90.000000  219.66784   \n",
       "4  2007         130000     120000  0.364006  1298.0   88.199997  112.77590   \n",
       "\n",
       "   seats  name_Ambassador Classic 2000 DSZ AC PS  \\\n",
       "0    5.0                                   False   \n",
       "1    5.0                                   False   \n",
       "2    5.0                                   False   \n",
       "3    5.0                                   False   \n",
       "4    5.0                                   False   \n",
       "\n",
       "   name_Ambassador Grand 1500 DSZ BSIII  ...  fuel_Diesel  fuel_LPG  \\\n",
       "0                                 False  ...         True     False   \n",
       "1                                 False  ...         True     False   \n",
       "2                                 False  ...        False     False   \n",
       "3                                 False  ...         True     False   \n",
       "4                                 False  ...        False     False   \n",
       "\n",
       "   fuel_Petrol  seller_type_Individual  seller_type_Trustmark Dealer  \\\n",
       "0        False                    True                         False   \n",
       "1        False                    True                         False   \n",
       "2         True                    True                         False   \n",
       "3        False                    True                         False   \n",
       "4         True                    True                         False   \n",
       "\n",
       "   transmission_Manual  owner_Fourth & Above Owner  owner_Second Owner  \\\n",
       "0                 True                       False               False   \n",
       "1                 True                       False                True   \n",
       "2                 True                       False               False   \n",
       "3                 True                       False               False   \n",
       "4                 True                       False               False   \n",
       "\n",
       "   owner_Test Drive Car  owner_Third Owner  \n",
       "0                 False              False  \n",
       "1                 False              False  \n",
       "2                 False               True  \n",
       "3                 False              False  \n",
       "4                 False              False  \n",
       "\n",
       "[5 rows x 1999 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8f12cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6324, 1998) (1582, 1998)\n",
      "(6324,) (1582,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(\"selling_price\", axis=1), data[\"selling_price\"], test_size=0.2, random_state=50\n",
    ")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6bae151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(random_state=50)\n",
    "model.fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a1b05528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rmse:  55002.85\n",
      "test rmse:  115864.59\n"
     ]
    }
   ],
   "source": [
    "print(\"train rmse: \", round(root_mean_squared_error(y_train, train_pred), 2))\n",
    "print(\"test rmse: \", round(root_mean_squared_error(y_test, test_pred),2 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896533ef",
   "metadata": {},
   "source": [
    "# K-폴드 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a989b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c0c280b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7906 entries, 0 to 8127\n",
      "Columns: 1999 entries, year to owner_Third Owner\n",
      "dtypes: bool(1991), float32(2), float64(3), int64(3)\n",
      "memory usage: 15.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "caf77ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1544ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7906 entries, 0 to 7905\n",
      "Columns: 1999 entries, year to owner_Third Owner\n",
      "dtypes: bool(1991), float32(2), float64(3), int64(3)\n",
      "memory usage: 15.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7ace1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "X = data.drop(\"selling_price\", axis=1)\n",
    "y = data[\"selling_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0795b3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1582 1583 1584 ... 7903 7904 7905] [   0    1    2 ... 1579 1580 1581]\n",
      "[   0    1    2 ... 7903 7904 7905] [1582 1583 1584 ... 3160 3161 3162]\n",
      "[   0    1    2 ... 7903 7904 7905] [3163 3164 3165 ... 4741 4742 4743]\n",
      "[   0    1    2 ... 7903 7904 7905] [4744 4745 4746 ... 6322 6323 6324]\n",
      "[   0    1    2 ... 6322 6323 6324] [6325 6326 6327 ... 7903 7904 7905]\n"
     ]
    }
   ],
   "source": [
    "for i, j in kf.split(X):\n",
    "  print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d61d8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "  X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "  y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "630e2522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6325, 1998) (1581, 1998)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ffff15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse_total = []\n",
    "test_rmse_total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1f567c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RandomForestRegressor(random_state=50)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_rmse_total.append(root_mean_squared_error(y_train, train_pred))\n",
    "    test_rmse_total.append(root_mean_squared_error(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f557cc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50532.92942767605,\n",
       " 55711.47280536497,\n",
       " 53790.697984038095,\n",
       " 54381.96940932169,\n",
       " 54501.24982446165]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d2a4839f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[173866.89158669254,\n",
       " 135496.1191916217,\n",
       " 125301.24567921956,\n",
       " 151130.81632352594,\n",
       " 142056.36112837086]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2d815a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57769.209003542295\n",
      "68558.9134577012\n",
      "62721.216716775125\n",
      "64950.984882393204\n",
      "64107.57630336222\n"
     ]
    }
   ],
   "source": [
    "train_rmse_total = []\n",
    "test_rmse_total = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RandomForestRegressor(n_estimators=300, max_depth=70, \n",
    "                                  min_samples_split=5, min_samples_leaf=1, n_jobs=-1,  random_state=50)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_rmse_total.append(root_mean_squared_error(y_train, train_pred))\n",
    "    test_rmse_total.append(root_mean_squared_error(y_test, test_pred))\n",
    "    print(train_rmse_total[len(train_rmse_total)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1ec09496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[173866.89158669254,\n",
       " 135496.1191916217,\n",
       " 125301.24567921956,\n",
       " 151130.81632352594,\n",
       " 142056.36112837086,\n",
       " 171739.74111250349,\n",
       " 171739.74111250349,\n",
       " 137296.59097606325,\n",
       " 123987.6149926097,\n",
       " 143623.36821695013,\n",
       " 139073.40831448277]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f13b41e",
   "metadata": {},
   "source": [
    "# 렌덤포레스트 분류 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b7c27a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5e58cf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_url = (\n",
    "    \"https://media.githubusercontent.com/media/musthave-ML10/data_source/main/wine.csv\"\n",
    ")\n",
    "data = pd.read_csv(file_url)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "acb8a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       176 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    int64  \n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          173 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    int64  \n",
      " 13  class                         178 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7af226a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dd0ee590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 14)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "442efc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 171 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       171 non-null    float64\n",
      " 1   malic_acid                    171 non-null    float64\n",
      " 2   ash                           171 non-null    float64\n",
      " 3   alcalinity_of_ash             171 non-null    float64\n",
      " 4   magnesium                     171 non-null    int64  \n",
      " 5   total_phenols                 171 non-null    float64\n",
      " 6   flavanoids                    171 non-null    float64\n",
      " 7   nonflavanoid_phenols          171 non-null    float64\n",
      " 8   proanthocyanins               171 non-null    float64\n",
      " 9   color_intensity               171 non-null    float64\n",
      " 10  hue                           171 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  171 non-null    float64\n",
      " 12  proline                       171 non-null    int64  \n",
      " 13  class                         171 non-null    int64  \n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 24.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1ae0bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "43c462d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6        127           2.80   \n",
       "1    13.16        2.36  2.67               18.6        101           2.80   \n",
       "2    14.37        1.95  2.50               16.8        113           3.85   \n",
       "3    13.24        2.59  2.87               21.0        118           2.80   \n",
       "4    14.20        1.76  2.45               15.2        112           3.27   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        3.24                  0.30             2.81             5.68  1.03   \n",
       "2        3.49                  0.24             2.18             7.80  0.86   \n",
       "3        2.69                  0.39             1.82             4.32  1.04   \n",
       "4        3.39                  0.34             1.97             6.75  1.05   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  class  \n",
       "0                          3.92     1065      0  \n",
       "1                          3.17     1185      0  \n",
       "2                          3.45     1480      0  \n",
       "3                          2.93      735      0  \n",
       "4                          2.85     1450      0  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b6bbf597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  :  0.914\n",
      "1.0  :  0.971\n",
      "1.0  :  0.941\n",
      "1.0  :  1.0\n",
      "1.0  :  0.971\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "X = data.drop(\"class\", axis=1)\n",
    "y = data[\"class\"]\n",
    "train_score_total = []\n",
    "test_score_total = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=50,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_score_total.append(accuracy_score(y_train, train_pred))\n",
    "    test_score_total.append(accuracy_score(y_test, test_pred))\n",
    "    print(\n",
    "        round(train_score_total[len(train_score_total) - 1], 3),\n",
    "        \" : \",\n",
    "        round(test_score_total[len(test_score_total) - 1], 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07914e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897338</td>\n",
       "      <td>-0.103226</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>-0.906977</td>\n",
       "      <td>1.487179</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.536023</td>\n",
       "      <td>-0.324324</td>\n",
       "      <td>1.013889</td>\n",
       "      <td>0.280936</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.915663</td>\n",
       "      <td>0.811983</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.083650</td>\n",
       "      <td>0.316129</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>-0.209302</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.639769</td>\n",
       "      <td>-0.216216</td>\n",
       "      <td>1.736111</td>\n",
       "      <td>0.294314</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>1.059917</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.003802</td>\n",
       "      <td>0.051613</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>-0.627907</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.448598</td>\n",
       "      <td>0.783862</td>\n",
       "      <td>-0.540541</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>1.003344</td>\n",
       "      <td>-0.318841</td>\n",
       "      <td>0.538153</td>\n",
       "      <td>1.669421</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.144487</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>1.025641</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.322767</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>-0.160535</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.130165</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.874525</td>\n",
       "      <td>-0.070968</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.726225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.056225</td>\n",
       "      <td>1.607438</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "0  0.897338   -0.103226  0.205882          -0.906977   1.487179   \n",
       "1  0.083650    0.316129  0.911765          -0.209302   0.153846   \n",
       "2  1.003802    0.051613  0.411765          -0.627907   0.769231   \n",
       "3  0.144487    0.464516  1.500000           0.348837   1.025641   \n",
       "4  0.874525   -0.070968  0.264706          -1.000000   0.717949   \n",
       "\n",
       "   total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0       0.467290    0.536023             -0.324324         1.013889   \n",
       "1       0.467290    0.639769             -0.216216         1.736111   \n",
       "2       1.448598    0.783862             -0.540541         0.861111   \n",
       "3       0.467290    0.322767              0.270270         0.361111   \n",
       "4       0.906542    0.726225              0.000000         0.569444   \n",
       "\n",
       "   color_intensity       hue  od280/od315_of_diluted_wines   proline  class  \n",
       "0         0.280936  0.202899                      0.915663  0.811983   -0.5  \n",
       "1         0.294314  0.173913                      0.313253  1.059917   -0.5  \n",
       "2         1.003344 -0.318841                      0.538153  1.669421   -0.5  \n",
       "3        -0.160535  0.202899                      0.120482  0.130165   -0.5  \n",
       "4         0.652174  0.231884                      0.056225  1.607438   -0.5  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_scaler = RobustScaler()\n",
    "data_scaled = rs_scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db4ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e22c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  :  0.857\n",
      "0.993  :  0.971\n",
      "1.0  :  0.941\n",
      "1.0  :  1.0\n",
      "1.0  :  0.971\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "X = data_scaled.drop(\"class\", axis=1)\n",
    "y = data[\"class\"]\n",
    "train_score_total = []\n",
    "test_score_total = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=50,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_score_total.append(accuracy_score(y_train, train_pred))\n",
    "    test_score_total.append(accuracy_score(y_test, test_pred))\n",
    "    print(\n",
    "        round(train_score_total[len(train_score_total) - 1], 3),\n",
    "        \" : \",\n",
    "        round(test_score_total[len(test_score_total) - 1], 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef67d6",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier  \n",
    "from sklearn.ensemble import BaggingClassifier  \n",
    "from sklearn.ensemble import GradientBoostingClassifier  \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier  \n",
    "from sklearn.ensemble import VotingClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "39b199a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AdaBoostClassifier in module sklearn.ensemble._weight_boosting:\n",
      "\n",
      "class AdaBoostClassifier(sklearn.utils._metadata_requests._RoutingNotSupportedMixin, sklearn.base.ClassifierMixin, BaseWeightBoosting)\n",
      " |  AdaBoostClassifier(estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='deprecated', random_state=None)\n",
      " |  \n",
      " |  An AdaBoost classifier.\n",
      " |  \n",
      " |  An AdaBoost [1]_ classifier is a meta-estimator that begins by fitting a\n",
      " |  classifier on the original dataset and then fits additional copies of the\n",
      " |  classifier on the same dataset but where the weights of incorrectly\n",
      " |  classified instances are adjusted such that subsequent classifiers focus\n",
      " |  more on difficult cases.\n",
      " |  \n",
      " |  This class implements the algorithm based on [2]_.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <adaboost>`.\n",
      " |  \n",
      " |  .. versionadded:: 0.14\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : object, default=None\n",
      " |      The base estimator from which the boosted ensemble is built.\n",
      " |      Support for sample weighting is required, as well as proper\n",
      " |      ``classes_`` and ``n_classes_`` attributes. If ``None``, then\n",
      " |      the base estimator is :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      " |      initialized with `max_depth=1`.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator` was renamed to `estimator`.\n",
      " |  \n",
      " |  n_estimators : int, default=50\n",
      " |      The maximum number of estimators at which boosting is terminated.\n",
      " |      In case of perfect fit, the learning procedure is stopped early.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  learning_rate : float, default=1.0\n",
      " |      Weight applied to each classifier at each boosting iteration. A higher\n",
      " |      learning rate increases the contribution of each classifier. There is\n",
      " |      a trade-off between the `learning_rate` and `n_estimators` parameters.\n",
      " |      Values must be in the range `(0.0, inf)`.\n",
      " |  \n",
      " |  algorithm : {'SAMME'}, default='SAMME'\n",
      " |      Use the SAMME discrete boosting algorithm.\n",
      " |  \n",
      " |      .. deprecated:: 1.6\n",
      " |          `algorithm` is deprecated and will be removed in version 1.8. This\n",
      " |          estimator only implements the 'SAMME' algorithm.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given at each `estimator` at each\n",
      " |      boosting iteration.\n",
      " |      Thus, it is only used when `estimator` exposes a `random_state`.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  estimator_ : estimator\n",
      " |      The base estimator from which the ensemble is grown.\n",
      " |  \n",
      " |      .. versionadded:: 1.2\n",
      " |         `base_estimator_` was renamed to `estimator_`.\n",
      " |  \n",
      " |  estimators_ : list of classifiers\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  n_classes_ : int\n",
      " |      The number of classes.\n",
      " |  \n",
      " |  estimator_weights_ : ndarray of floats\n",
      " |      Weights for each estimator in the boosted ensemble.\n",
      " |  \n",
      " |  estimator_errors_ : ndarray of floats\n",
      " |      Classification error for each estimator in the boosted\n",
      " |      ensemble.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances if supported by the\n",
      " |      ``estimator`` (when based on decision trees).\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  AdaBoostRegressor : An AdaBoost regressor that begins by fitting a\n",
      " |      regressor on the original dataset and then fits additional copies of\n",
      " |      the regressor on the same dataset but where the weights of instances\n",
      " |      are adjusted according to the error of the current prediction.\n",
      " |  \n",
      " |  GradientBoostingClassifier : GB builds an additive model in a forward\n",
      " |      stage-wise fashion. Regression trees are fit on the negative gradient\n",
      " |      of the binomial or multinomial deviance loss function. Binary\n",
      " |      classification is a special case where only a single regression tree is\n",
      " |      induced.\n",
      " |  \n",
      " |  sklearn.tree.DecisionTreeClassifier : A non-parametric supervised learning\n",
      " |      method used for classification.\n",
      " |      Creates a model that predicts the value of a target variable by\n",
      " |      learning simple decision rules inferred from the data features.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] Y. Freund, R. Schapire, \"A Decision-Theoretic Generalization of\n",
      " |         on-Line Learning and an Application to Boosting\", 1995.\n",
      " |  \n",
      " |  .. [2] :doi:`J. Zhu, H. Zou, S. Rosset, T. Hastie, \"Multi-class adaboost.\"\n",
      " |         Statistics and its Interface 2.3 (2009): 349-360.\n",
      " |         <10.4310/SII.2009.v2.n3.a8>`\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import AdaBoostClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  AdaBoostClassifier(n_estimators=100, random_state=0)\n",
      " |  >>> clf.predict([[0, 0, 0, 0]])\n",
      " |  array([1])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.96...\n",
      " |  \n",
      " |  For a detailed example of using AdaBoost to fit a sequence of DecisionTrees\n",
      " |  as weaklearners, please refer to\n",
      " |  :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_multiclass.py`.\n",
      " |  \n",
      " |  For a detailed example of using AdaBoost to fit a non-linearly seperable\n",
      " |  classification dataset composed of two Gaussian quantiles clusters, please\n",
      " |  refer to :ref:`sphx_glr_auto_examples_ensemble_plot_adaboost_twoclass.py`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AdaBoostClassifier\n",
      " |      sklearn.utils._metadata_requests._RoutingNotSupportedMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseWeightBoosting\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='deprecated', random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray of shape of (n_samples, k)\n",
      " |          The decision function of the input samples. The order of\n",
      " |          outputs is the same as that of the :term:`classes_` attribute.\n",
      " |          Binary classification is a special cases with ``k == 1``,\n",
      " |          otherwise ``k==n_classes``. For binary classification,\n",
      " |          values closer to -1 or 1 mean more like the first or second\n",
      " |          class in ``classes_``, respectively.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict classes for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the weighted mean\n",
      " |      prediction of the classifiers in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class log-probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the :term:`classes_` attribute.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the :term:`classes_` attribute.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._weight_boosting.AdaBoostClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._weight_boosting.AdaBoostClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._weight_boosting.AdaBoostClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._weight_boosting.AdaBoostClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each boosting iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each boosting iteration.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      score : generator of ndarray of shape (n_samples, k)\n",
      " |          The decision function of the input samples. The order of\n",
      " |          outputs is the same of that of the :term:`classes_` attribute.\n",
      " |          Binary classification is a special cases with ``k == 1``,\n",
      " |          otherwise ``k==n_classes``. For binary classification,\n",
      " |          values closer to -1 or 1 mean more like the first or second\n",
      " |          class in ``classes_``, respectively.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Return staged predictions for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is computed as the weighted mean\n",
      " |      prediction of the classifiers in the ensemble.\n",
      " |      \n",
      " |      This generator method yields the ensemble prediction after each\n",
      " |      iteration of boosting and therefore allows monitoring, such as to\n",
      " |      determine the prediction on a test set after each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample is computed as\n",
      " |      the weighted mean predicted class probabilities of the classifiers\n",
      " |      in the ensemble.\n",
      " |      \n",
      " |      This generator method yields the ensemble predicted class probabilities\n",
      " |      after each iteration of boosting and therefore allows monitoring, such\n",
      " |      as to determine the predicted class probabilities on a test set after\n",
      " |      each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      p : generator of ndarray of shape (n_samples,)\n",
      " |          The class probabilities of the input samples. The order of\n",
      " |          outputs is the same of that of the :term:`classes_` attribute.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._RoutingNotSupportedMixin:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Raise `NotImplementedError`.\n",
      " |      \n",
      " |      This estimator does not support metadata routing yet.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._metadata_requests._RoutingNotSupportedMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __sklearn_tags__(self)\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseWeightBoosting:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a boosted classifier/regressor from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          The target values.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, the sample weights are initialized to\n",
      " |          1 / n_samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  staged_score(self, X, y, sample_weight=None)\n",
      " |      Return staged scores for X, y.\n",
      " |      \n",
      " |      This generator method yields the ensemble score after each iteration of\n",
      " |      boosting and therefore allows monitoring, such as to determine the\n",
      " |      score on a test set after each boost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
      " |          DOK, or LIL. COO, DOK, and LIL are converted to CSR.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      z : float\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseWeightBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The feature importances.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "deb1b4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  :  0.943\n",
      "1.0  :  0.882\n",
      "1.0  :  1.0\n",
      "1.0  :  0.824\n",
      "1.0  :  0.853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "X = data_scaled.drop(\"class\", axis=1)\n",
    "y = data[\"class\"]\n",
    "train_score_total = []\n",
    "test_score_total = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = AdaBoostClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=1.0,\n",
    "        random_state=50,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_score_total.append(accuracy_score(y_train, train_pred))\n",
    "    test_score_total.append(accuracy_score(y_test, test_pred))\n",
    "    print(\n",
    "        round(train_score_total[len(train_score_total) - 1], 3),\n",
    "        \" : \",\n",
    "        round(test_score_total[len(test_score_total) - 1], 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95da304",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "103ff717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GradientBoostingClassifier in module sklearn.ensemble._gb:\n",
      "\n",
      "class GradientBoostingClassifier(sklearn.base.ClassifierMixin, BaseGradientBoosting)\n",
      " |  GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |  \n",
      " |  Gradient Boosting for classification.\n",
      " |  \n",
      " |  This algorithm builds an additive model in a forward stage-wise fashion; it\n",
      " |  allows for the optimization of arbitrary differentiable loss functions. In\n",
      " |  each stage ``n_classes_`` regression trees are fit on the negative gradient\n",
      " |  of the loss function, e.g. binary or multiclass log loss. Binary\n",
      " |  classification is a special case where only a single regression tree is\n",
      " |  induced.\n",
      " |  \n",
      " |  :class:`~sklearn.ensemble.HistGradientBoostingClassifier` is a much faster variant\n",
      " |  of this algorithm for intermediate and large datasets (`n_samples >= 10_000`) and\n",
      " |  supports monotonic constraints.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'log_loss', 'exponential'}, default='log_loss'\n",
      " |      The loss function to be optimized. 'log_loss' refers to binomial and\n",
      " |      multinomial deviance, the same as used in logistic regression.\n",
      " |      It is a good choice for classification with probabilistic outputs.\n",
      " |      For loss 'exponential', gradient boosting recovers the AdaBoost algorithm.\n",
      " |  \n",
      " |  learning_rate : float, default=0.1\n",
      " |      Learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |  n_estimators : int, default=100\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  subsample : float, default=1.0\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |      Values must be in the range `(0.0, 1.0]`.\n",
      " |  \n",
      " |  criterion : {'friedman_mse', 'squared_error'}, default='friedman_mse'\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      'friedman_mse' for the mean squared error with improvement score by\n",
      " |      Friedman, 'squared_error' for mean squared error. The default value of\n",
      " |      'friedman_mse' is generally the best as it can provide a better\n",
      " |      approximation in some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, values must be in the range `[2, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`\n",
      " |        will be `ceil(min_samples_split * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`\n",
      " |        will be `ceil(min_samples_leaf * n_samples)`.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |      Values must be in the range `[0.0, 0.5]`.\n",
      " |  \n",
      " |  max_depth : int or None, default=3\n",
      " |      Maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |      If int, values must be in the range `[1, inf)`.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  init : estimator or 'zero', default=None\n",
      " |      An estimator object that is used to compute the initial predictions.\n",
      " |      ``init`` has to provide :term:`fit` and :term:`predict_proba`. If\n",
      " |      'zero', the initial raw predictions are set to zero. By default, a\n",
      " |      ``DummyEstimator`` predicting the classes priors is used.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the random seed given to each Tree estimator at each\n",
      " |      boosting iteration.\n",
      " |      In addition, it controls the random permutation of the features at\n",
      " |      each split (see Notes for more details).\n",
      " |      It also controls the random splitting of the training data to obtain a\n",
      " |      validation set if `n_iter_no_change` is not None.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  max_features : {'sqrt', 'log2'}, int or float, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, values must be in the range `[1, inf)`.\n",
      " |      - If float, values must be in the range `(0.0, 1.0]` and the features\n",
      " |        considered at each split will be `max(1, int(max_features * n_features_in_))`.\n",
      " |      - If 'sqrt', then `max_features=sqrt(n_features)`.\n",
      " |      - If 'log2', then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |      Values must be in the range `[0, inf)`.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      Values must be in the range `[2, inf)`.\n",
      " |      If `None`, then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Values must be in the range `(0.0, 1.0)`.\n",
      " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default=None\n",
      " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      " |      to terminate training when validation score is not improving. By\n",
      " |      default it is set to None to disable early stopping. If set to a\n",
      " |      number, it will set aside ``validation_fraction`` size of the training\n",
      " |      data as validation and terminate training when validation score is not\n",
      " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
      " |      iterations. The split is stratified.\n",
      " |      Values must be in the range `[1, inf)`.\n",
      " |      See\n",
      " |      :ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for the early stopping. When the loss is not improving\n",
      " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      " |      number), the training stops.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed.\n",
      " |      Values must be in the range `[0.0, inf)`.\n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details. See\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`\n",
      " |      for an example of such pruning.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  n_estimators_ : int\n",
      " |      The number of estimators as selected by early stopping (if\n",
      " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_trees_per_iteration_ : int\n",
      " |      The number of trees that are built at each iteration. For binary classifiers,\n",
      " |      this is always 1.\n",
      " |  \n",
      " |      .. versionadded:: 1.4.0\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_improvement_ : ndarray of shape (n_estimators,)\n",
      " |      The improvement in loss on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |      Only available if ``subsample < 1.0``.\n",
      " |  \n",
      " |  oob_scores_ : ndarray of shape (n_estimators,)\n",
      " |      The full history of the loss values on the out-of-bag\n",
      " |      samples. Only available if `subsample < 1.0`.\n",
      " |  \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      The last value of the loss on the out-of-bag samples. It is\n",
      " |      the same as `oob_scores_[-1]`. Only available if `subsample < 1.0`.\n",
      " |  \n",
      " |      .. versionadded:: 1.3\n",
      " |  \n",
      " |  train_score_ : ndarray of shape (n_estimators,)\n",
      " |      The i-th score ``train_score_[i]`` is the loss of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the loss on the training data.\n",
      " |  \n",
      " |  init_ : estimator\n",
      " |      The estimator that provides the initial predictions. Set via the ``init``\n",
      " |      argument.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor of             shape (n_estimators, ``n_trees_per_iteration_``)\n",
      " |      The collection of fitted sub-estimators. ``n_trees_per_iteration_`` is 1 for\n",
      " |      binary classification, otherwise ``n_classes``.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_classes_ : int\n",
      " |      The number of classes.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  HistGradientBoostingClassifier : Histogram-based Gradient Boosting\n",
      " |      Classification Tree.\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  RandomForestClassifier : A meta-estimator that fits a number of decision\n",
      " |      tree classifiers on various sub-samples of the dataset and uses\n",
      " |      averaging to improve the predictive accuracy and control over-fitting.\n",
      " |  AdaBoostClassifier : A meta-estimator that begins by fitting a classifier\n",
      " |      on the original dataset and then fits additional copies of the\n",
      " |      classifier on the same dataset where the weights of incorrectly\n",
      " |      classified instances are adjusted such that subsequent classifiers\n",
      " |      focus more on difficult cases.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  The following example shows how to fit a gradient boosting classifier with\n",
      " |  100 decision stumps as weak learners.\n",
      " |  \n",
      " |  >>> from sklearn.datasets import make_hastie_10_2\n",
      " |  >>> from sklearn.ensemble import GradientBoostingClassifier\n",
      " |  \n",
      " |  >>> X, y = make_hastie_10_2(random_state=0)\n",
      " |  >>> X_train, X_test = X[:2000], X[2000:]\n",
      " |  >>> y_train, y_test = y[:2000], y[2000:]\n",
      " |  \n",
      " |  >>> clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
      " |  ...     max_depth=1, random_state=0).fit(X_train, y_train)\n",
      " |  >>> clf.score(X_test, y_test)\n",
      " |  0.913...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseGradientBoosting\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : ndarray of shape (n_samples, n_classes) or (n_samples,)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          order of the classes corresponds to that in the attribute\n",
      " |          :term:`classes_`. Regression and binary classification produce an\n",
      " |          array of shape (n_samples,).\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |  \n",
      " |  set_fit_request(self: sklearn.ensemble._gb.GradientBoostingClassifier, *, monitor: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._gb.GradientBoostingClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      monitor : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``monitor`` parameter in ``fit``.\n",
      " |      \n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  set_score_request(self: sklearn.ensemble._gb.GradientBoostingClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.ensemble._gb.GradientBoostingClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |      \n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      The options for each parameter are:\n",
      " |      \n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |      \n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |      \n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |      \n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |      \n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |      \n",
      " |      .. versionadded:: 1.3\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      score : generator of ndarray of shape (n_samples, k)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |          Regression and binary classification are special cases with\n",
      " |          ``k == 1``, otherwise ``k==n_classes``.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict class at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      y : generator of ndarray of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __sklearn_tags__(self)\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples, n_estimators, n_classes)\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |          In the case of binary classification n_classes is 1.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (strings or integers in classification, real numbers\n",
      " |          in regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, default=None\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshotting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bb10b171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0  :  0.943\n",
      "1.0  :  0.912\n",
      "1.0  :  0.735\n",
      "1.0  :  0.912\n",
      "1.0  :  0.882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "X = data_scaled.drop(\"class\", axis=1)\n",
    "y = data[\"class\"]\n",
    "train_score_total = []\n",
    "test_score_total = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    model = GradientBoostingClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=50,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    train_score_total.append(accuracy_score(y_train, train_pred))\n",
    "    test_score_total.append(accuracy_score(y_test, test_pred))\n",
    "    print(\n",
    "        round(train_score_total[len(train_score_total) - 1], 3),\n",
    "        \" : \",\n",
    "        round(test_score_total[len(test_score_total) - 1], 3),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58280bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
