{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac m1 : brew install cmake libomp\n",
    "!uv add xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ec136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error  # 루트 제곱 평균 오차\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from sklearn.preprocessing import StandardScaler  # 평균 0, 표준편차 1\n",
    "from sklearn.preprocessing import MinMaxScaler  # 백분위\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb157ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"https://media.githubusercontent.com/media/musthave-ML10/data_source/main/dating.csv\"\n",
    "data = pd.read_csv(file_url)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56e2e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fe1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409f1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data.describe(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863fe4c1",
   "metadata": {},
   "source": [
    "# 전처리 : 결측치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc734d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(\n",
    "    subset=[\n",
    "        \"pref_o_attractive\",\n",
    "        \"pref_o_sincere\",\n",
    "        \"pref_o_intelligence\",\n",
    "        \"pref_o_funny\",\n",
    "        \"pref_o_ambitious\",\n",
    "        \"pref_o_shared_interests\",\n",
    "        \"attractive_o\",\n",
    "        \"sincere_o\",\n",
    "        \"intelligence_o\",\n",
    "        \"funny_o\",\n",
    "        \"ambitous_o\",\n",
    "        \"shared_interests_o\",\n",
    "        \"attractive_important\",\n",
    "        \"sincere_important\",\n",
    "        \"intellicence_important\",\n",
    "        \"funny_important\",\n",
    "        \"ambtition_important\",\n",
    "        \"shared_interests_important\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534efea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(-99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699225b3",
   "metadata": {},
   "source": [
    "# 전처리 : 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_gap(x):\n",
    "  if x[\"age\"] == -99:\n",
    "    return -99\n",
    "  elif x[\"age_o\"] == -99:\n",
    "    return -99\n",
    "  elif x[\"gender\"] == \"female\":\n",
    "    return x[\"age_o\"] - x[\"age\"]\n",
    "  else:\n",
    "    return x[\"age\"] - x[\"age_o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dcb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.loc[9, [\"gender\", \"age\", \"age_o\"]])\n",
    "print(age_gap(data.loc[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_gap\"] = data.apply(age_gap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_gap\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159b3577",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"age_gap_abs\"] = abs(data[\"age_gap\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60382133",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25537462",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race(x):\n",
    "    if x[\"race\"] == -99:\n",
    "        return -99\n",
    "    elif x[\"race_o\"] == -99:\n",
    "        return -99\n",
    "    elif x[\"race\"] == x[\"race_o\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00894367",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"same_race\"] = data.apply(same_race, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_race_point(x):\n",
    "    if x[\"same_race\"] == -99:\n",
    "        return -99\n",
    "    else:\n",
    "        return x[\"same_race\"] * x[\"importance_same_race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"same_race_point\"] = data.apply(same_race_point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09859769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating(data, importance, score):\n",
    "  if data[importance] == -99:\n",
    "    return -99\n",
    "  elif data[score] == -99:\n",
    "    return -99\n",
    "  else:\n",
    "    return data[importance] * data[score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ed01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns[26:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a512da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상대방의 중요도\n",
    "partner_imp = data.columns[8:14]\n",
    "# 본인에 대한 상대방의 평가\n",
    "partner_rate_me = data.columns[14:20]\n",
    "# 본인의 중요도\n",
    "my_imp = data.columns[20:26]\n",
    "# 상대방에 대한 본인의 평가\n",
    "my_rate_partner = data.columns[26:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333d146",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_partner = [\n",
    "    \"attractive_p\",\n",
    "    \"sincere_p\",\n",
    "    \"intelligence_p\",\n",
    "    \"funny_p\",\n",
    "    \"ambition_p\",\n",
    "    \"shared_interests_p\",\n",
    "]\n",
    "\n",
    "new_label_me = [\n",
    "    \"attractive_m\",\n",
    "    \"sincere_m\",\n",
    "    \"intelligence_m\",\n",
    "    \"funny_m\",\n",
    "    \"ambition_m\",\n",
    "    \"shared_interests_m\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7762cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val1, val2 in zip(new_label_partner,partner_imp,partner_rate_me):\n",
    "    print(idx,\" & \" ,val1 ,\" & \",val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val1, val2 in zip(new_label_me,my_imp,my_rate_partner):\n",
    "    print(idx,\" & \" ,val1 ,\" & \",val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val1, val2 in zip(new_label_partner, partner_imp, partner_rate_me):\n",
    "    data[idx] = data.apply(lambda x : rating(x,val1,val2) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val1, val2 in zip(new_label_me, my_imp, my_rate_partner):\n",
    "    data[idx] = data.apply(lambda x: rating(x, val1, val2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d32d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e822f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data,columns=[\"gender\",\"race\",\"race_o\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51685c80",
   "metadata": {},
   "source": [
    "# 모델 학습 및 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\"match\",axis=1),data[\"match\"],test_size=.3,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06971291",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(xgb.XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0792112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  xgb.XGBClassifier(n_estimators = 500, max_depth=5,random_state=20)\n",
    "model.fit(X_train,y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7faed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train score : \" , accuracy_score(train_pred,y_train))\n",
    "print(\"test score : \", accuracy_score(test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537cc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc , roc_auc_score, f1_score,classification_report\n",
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accc62e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddd157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c60f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = data.loc[\n",
    "    :,\n",
    "    [\n",
    "        \"interests_correlate\",\n",
    "        \"expected_happy_with_sd_people\",\n",
    "        \"expected_num_interested_in_me\",\n",
    "        \"like\",\n",
    "        \"guess_prob_liked\",\n",
    "        \"met\",\n",
    "        \"match\",\n",
    "        \"age_gap_abs\",\n",
    "        \"same_race\",\n",
    "        \"same_race_point\",\n",
    "        \"attractive_p\",\n",
    "        \"sincere_p\",\n",
    "        \"intelligence_p\",\n",
    "        \"funny_p\",\n",
    "        \"ambition_p\",\n",
    "        \"shared_interests_p\",\n",
    "        \"attractive_m\",\n",
    "        \"sincere_m\",\n",
    "        \"intelligence_m\",\n",
    "        \"funny_m\",\n",
    "        \"ambition_m\",\n",
    "        \"shared_interests_m\",\n",
    "        \"gender_male\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1c41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_subset.shape,data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_scaler = RobustScaler()\n",
    "data_subset_scaled = rs_scaler.fit_transform(data_subset)\n",
    "data_subset_scaled = pd.DataFrame(data_subset_scaled, columns=data_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf25df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "837fbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_subset_scaled.drop(\"match\", axis=1), data_subset[\"match\"], test_size=0.3, random_state=20\n",
    ")\n",
    "model = xgb.XGBClassifier(n_estimators=1000, max_depth=5, random_state=20)\n",
    "model.fit(X_train, y_train)\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b4f71aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      1686\n",
      "           1       0.58      0.39      0.47       363\n",
      "\n",
      "    accuracy                           0.84      2049\n",
      "   macro avg       0.73      0.67      0.69      2049\n",
      "weighted avg       0.83      0.84      0.83      2049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f1409c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5169c",
   "metadata": {},
   "source": [
    "# 하이퍼파라미터 최적화 : 그리드 서치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "717d8d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(sklearn.base.ClassifierMixin, XGBModel)\n",
      " |  XGBClassifier(\n",
      " |      *,\n",
      " |      objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic',\n",
      " |      **kwargs: Any\n",
      " |  ) -> None\n",
      " |\n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  See :doc:`/python/sklearn_estimator` for more information.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |\n",
      " |      n_estimators : Optional[int]\n",
      " |          Number of boosting rounds.\n",
      " |\n",
      " |      max_depth :  typing.Optional[int]\n",
      " |\n",
      " |          Maximum tree depth for base learners.\n",
      " |\n",
      " |      max_leaves : typing.Optional[int]\n",
      " |\n",
      " |          Maximum number of leaves; 0 indicates no limit.\n",
      " |\n",
      " |      max_bin : typing.Optional[int]\n",
      " |\n",
      " |          If using histogram-based algorithm, maximum number of bins per feature\n",
      " |\n",
      " |      grow_policy : typing.Optional[str]\n",
      " |\n",
      " |          Tree growing policy.\n",
      " |\n",
      " |          - depthwise: Favors splitting at nodes closest to the node,\n",
      " |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      " |\n",
      " |      learning_rate : typing.Optional[float]\n",
      " |\n",
      " |          Boosting learning rate (xgb's \"eta\")\n",
      " |\n",
      " |      verbosity : typing.Optional[int]\n",
      " |\n",
      " |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |\n",
      " |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      " |\n",
      " |          Specify the learning task and the corresponding learning objective or a custom\n",
      " |          objective function to be used.\n",
      " |\n",
      " |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      " |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      " |          function signatures.\n",
      " |\n",
      " |      booster: typing.Optional[str]\n",
      " |\n",
      " |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      " |\n",
      " |      tree_method : typing.Optional[str]\n",
      " |\n",
      " |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      " |          default, XGBoost will choose the most conservative option available.  It's\n",
      " |          recommended to study this option from the parameters document :doc:`tree method\n",
      " |          </treemethod>`\n",
      " |\n",
      " |      n_jobs : typing.Optional[int]\n",
      " |\n",
      " |          Number of parallel threads used to run xgboost.  When used with other\n",
      " |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      " |          parallelize and balance the threads.  Creating thread contention will\n",
      " |          significantly slow down both algorithms.\n",
      " |\n",
      " |      gamma : typing.Optional[float]\n",
      " |\n",
      " |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      " |          a leaf node of the tree.\n",
      " |\n",
      " |      min_child_weight : typing.Optional[float]\n",
      " |\n",
      " |          Minimum sum of instance weight(hessian) needed in a child.\n",
      " |\n",
      " |      max_delta_step : typing.Optional[float]\n",
      " |\n",
      " |          Maximum delta step we allow each tree's weight estimation to be.\n",
      " |\n",
      " |      subsample : typing.Optional[float]\n",
      " |\n",
      " |          Subsample ratio of the training instance.\n",
      " |\n",
      " |      sampling_method : typing.Optional[str]\n",
      " |\n",
      " |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      " |\n",
      " |          - ``uniform``: Select random training instances uniformly.\n",
      " |          - ``gradient_based``: Select random training instances with higher probability\n",
      " |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      " |\n",
      " |      colsample_bytree : typing.Optional[float]\n",
      " |\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |\n",
      " |      colsample_bylevel : typing.Optional[float]\n",
      " |\n",
      " |          Subsample ratio of columns for each level.\n",
      " |\n",
      " |      colsample_bynode : typing.Optional[float]\n",
      " |\n",
      " |          Subsample ratio of columns for each split.\n",
      " |\n",
      " |      reg_alpha : typing.Optional[float]\n",
      " |\n",
      " |          L1 regularization term on weights (xgb's alpha).\n",
      " |\n",
      " |      reg_lambda : typing.Optional[float]\n",
      " |\n",
      " |          L2 regularization term on weights (xgb's lambda).\n",
      " |\n",
      " |      scale_pos_weight : typing.Optional[float]\n",
      " |          Balancing of positive and negative weights.\n",
      " |\n",
      " |      base_score : typing.Optional[float]\n",
      " |\n",
      " |          The initial prediction score of all instances, global bias.\n",
      " |\n",
      " |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      " |\n",
      " |          Random number seed.\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      " |             it uses Hogwild algorithm.\n",
      " |\n",
      " |      missing : float\n",
      " |\n",
      " |          Value in the data which needs to be present as a missing value. Default to\n",
      " |          :py:data:`numpy.nan`.\n",
      " |\n",
      " |      num_parallel_tree: typing.Optional[int]\n",
      " |\n",
      " |          Used for boosting random forest.\n",
      " |\n",
      " |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      " |\n",
      " |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      " |          for more information.\n",
      " |\n",
      " |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      " |\n",
      " |          Constraints for interaction representing permitted interactions.  The\n",
      " |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      " |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      " |          allowed to interact with each other.  See :doc:`tutorial\n",
      " |          </tutorials/feature_interaction_constraint>` for more information\n",
      " |\n",
      " |      importance_type: typing.Optional[str]\n",
      " |\n",
      " |          The feature importance type for the feature_importances\\_ property:\n",
      " |\n",
      " |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      " |            \"total_cover\".\n",
      " |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      " |            coefficients without bias.\n",
      " |\n",
      " |      device : typing.Optional[str]\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      " |\n",
      " |      validate_parameters : typing.Optional[bool]\n",
      " |\n",
      " |          Give warnings for unknown parameter.\n",
      " |\n",
      " |      enable_categorical : bool\n",
      " |\n",
      " |          See the same parameter of :py:class:`DMatrix` for details.\n",
      " |\n",
      " |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      " |\n",
      " |          .. versionadded:: 1.7.0\n",
      " |\n",
      " |          Used for specifying feature types without constructing a dataframe. See\n",
      " |          :py:class:`DMatrix` for details.\n",
      " |\n",
      " |      feature_weights : Optional[ArrayLike]\n",
      " |\n",
      " |          Weight for each feature, defines the probability of each feature being selected\n",
      " |          when colsample is being used.  All values must be greater than 0, otherwise a\n",
      " |          `ValueError` is thrown.\n",
      " |\n",
      " |      max_cat_to_onehot : Optional[int]\n",
      " |\n",
      " |          .. versionadded:: 1.6.0\n",
      " |\n",
      " |          .. note:: This parameter is experimental\n",
      " |\n",
      " |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      " |          for categorical data.  When number of categories is lesser than the threshold\n",
      " |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      " |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      " |          categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |\n",
      " |      max_cat_threshold : typing.Optional[int]\n",
      " |\n",
      " |          .. versionadded:: 1.7.0\n",
      " |\n",
      " |          .. note:: This parameter is experimental\n",
      " |\n",
      " |          Maximum number of categories considered for each split. Used only by\n",
      " |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      " |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |\n",
      " |      multi_strategy : typing.Optional[str]\n",
      " |\n",
      " |          .. versionadded:: 2.0.0\n",
      " |\n",
      " |          .. note:: This parameter is working-in-progress.\n",
      " |\n",
      " |          The strategy used for training multi-target models, including multi-target\n",
      " |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      " |          more information.\n",
      " |\n",
      " |          - ``one_output_per_tree``: One model for each target.\n",
      " |          - ``multi_output_tree``:  Use multi-target trees.\n",
      " |\n",
      " |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      " |\n",
      " |          .. versionadded:: 1.6.0\n",
      " |\n",
      " |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      " |          string or list of strings as names of predefined metric in XGBoost (See\n",
      " |          :doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      " |          other user defined metric that looks like `sklearn.metrics`.\n",
      " |\n",
      " |          If custom objective is also provided, then custom metric should implement the\n",
      " |          corresponding reverse link function.\n",
      " |\n",
      " |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      " |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      " |          will minimize the result during early stopping.\n",
      " |\n",
      " |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      " |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      " |\n",
      " |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      " |          information.\n",
      " |\n",
      " |          .. code-block:: python\n",
      " |\n",
      " |              from sklearn.datasets import load_diabetes\n",
      " |              from sklearn.metrics import mean_absolute_error\n",
      " |              X, y = load_diabetes(return_X_y=True)\n",
      " |              reg = xgb.XGBRegressor(\n",
      " |                  tree_method=\"hist\",\n",
      " |                  eval_metric=mean_absolute_error,\n",
      " |              )\n",
      " |              reg.fit(X, y, eval_set=[(X, y)])\n",
      " |\n",
      " |      early_stopping_rounds : typing.Optional[int]\n",
      " |\n",
      " |          .. versionadded:: 1.6.0\n",
      " |\n",
      " |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      " |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      " |            least one item in **eval_set** in :py:meth:`fit`.\n",
      " |\n",
      " |          - If early stopping occurs, the model will have two additional attributes:\n",
      " |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      " |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      " |            number of trees during inference. If users want to access the full model\n",
      " |            (including trees built after early stopping), they can specify the\n",
      " |            `iteration_range` in these inference methods. In addition, other utilities\n",
      " |            like model plotting can also use the entire model.\n",
      " |\n",
      " |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      " |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      " |\n",
      " |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      " |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      " |            metric will be used for early stopping.\n",
      " |\n",
      " |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      " |\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using\n",
      " |          :ref:`Callback API <callback_api>`.\n",
      " |\n",
      " |          .. note::\n",
      " |\n",
      " |             States in callback are not preserved during training, which means callback\n",
      " |             objects can not be reused for multiple training sessions without\n",
      " |             reinitialization or deepcopy.\n",
      " |\n",
      " |          .. code-block:: python\n",
      " |\n",
      " |              for params in parameters_grid:\n",
      " |                  # be sure to (re)initialize the callbacks before each run\n",
      " |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      " |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      " |                  reg.fit(X, y)\n",
      " |\n",
      " |      kwargs : typing.Optional[typing.Any]\n",
      " |\n",
      " |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      " |          can be found :doc:`here </parameter>`.\n",
      " |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      " |          dict simultaneously will result in a TypeError.\n",
      " |\n",
      " |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |\n",
      " |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      " |              that parameters passed via this argument will interact properly\n",
      " |              with scikit-learn.\n",
      " |\n",
      " |          .. note::  Custom objective function\n",
      " |\n",
      " |              A custom objective function can be provided for the ``objective``\n",
      " |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      " |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      " |              -> [grad, hess]``:\n",
      " |\n",
      " |              y_true: array_like of shape [n_samples]\n",
      " |                  The target values\n",
      " |              y_pred: array_like of shape [n_samples]\n",
      " |                  The predicted values\n",
      " |              sample_weight :\n",
      " |                  Optional sample weights.\n",
      " |\n",
      " |              grad: array_like of shape [n_samples]\n",
      " |                  The value of the gradient for each sample point.\n",
      " |              hess: array_like of shape [n_samples]\n",
      " |                  The value of the second derivative for each sample point\n",
      " |\n",
      " |              Note that, if the custom objective produces negative values for\n",
      " |              the Hessian, these will be clipped. If the objective is non-convex,\n",
      " |              one might also consider using the expected Hessian (Fisher\n",
      " |              information) instead.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      *,\n",
      " |      objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic',\n",
      " |      **kwargs: Any\n",
      " |  ) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  __sklearn_tags__(self) -> sklearn.utils._tags.Tags\n",
      " |\n",
      " |  fit(\n",
      " |      self,\n",
      " |      X: Any,\n",
      " |      y: Any,\n",
      " |      *,\n",
      " |      sample_weight: Optional[Any] = None,\n",
      " |      base_margin: Optional[Any] = None,\n",
      " |      eval_set: Optional[Sequence[Tuple[Any, Any]]] = None,\n",
      " |      verbose: Union[bool, int, NoneType] = True,\n",
      " |      xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None,\n",
      " |      sample_weight_eval_set: Optional[Sequence[Any]] = None,\n",
      " |      base_margin_eval_set: Optional[Sequence[Any]] = None,\n",
      " |      feature_weights: Optional[Any] = None\n",
      " |  ) -> 'XGBClassifier'\n",
      " |      Fit gradient boosting classifier.\n",
      " |\n",
      " |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      " |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      " |      pass ``xgb_model`` argument.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Input feature matrix. See :ref:`py-data` for a list of supported types.\n",
      " |\n",
      " |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      " |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      " |          for conserving memory. However, this has performance implications when the\n",
      " |          device of input data is not matched with algorithm. For instance, if the\n",
      " |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      " |          data is first processed on CPU then transferred to GPU.\n",
      " |      y :\n",
      " |          Labels\n",
      " |      sample_weight :\n",
      " |          instance weights\n",
      " |      base_margin :\n",
      " |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      " |      eval_set :\n",
      " |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      " |          metrics will be computed.\n",
      " |          Validation metrics will help us track the performance of the model.\n",
      " |\n",
      " |      verbose :\n",
      " |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      " |          measured on the validation set is printed to stdout at each boosting stage.\n",
      " |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      " |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      " |          by using `early_stopping_rounds` is also printed.\n",
      " |      xgb_model :\n",
      " |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      sample_weight_eval_set :\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      " |          object storing instance weights for the i-th validation set.\n",
      " |      base_margin_eval_set :\n",
      " |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      " |          object storing base margin for the i-th validation set.\n",
      " |      feature_weights :\n",
      " |\n",
      " |          .. deprecated:: 3.0.0\n",
      " |\n",
      " |          Use `feature_weights` in :py:meth:`__init__` or :py:meth:`set_params`\n",
      " |          instead.\n",
      " |\n",
      " |  predict(\n",
      " |      self,\n",
      " |      X: Any,\n",
      " |      *,\n",
      " |      output_margin: bool = False,\n",
      " |      validate_features: bool = True,\n",
      " |      base_margin: Optional[Any] = None,\n",
      " |      iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None\n",
      " |  ) -> Any\n",
      " |      Predict with `X`.  If the model is trained with early stopping, then\n",
      " |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      " |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      " |      devices between the data and the estimator don't match.\n",
      " |\n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Data to predict with. See :ref:`py-data` for a list of supported types.\n",
      " |      output_margin :\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      " |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      " |          are used in this prediction.\n",
      " |\n",
      " |          .. versionadded:: 1.4.0\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction\n",
      " |\n",
      " |  predict_proba(\n",
      " |      self,\n",
      " |      X: Any,\n",
      " |      validate_features: bool = True,\n",
      " |      base_margin: Optional[Any] = None,\n",
      " |      iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None\n",
      " |  ) -> numpy.ndarray\n",
      " |      Predict the probability of each `X` example being of a given class. If the\n",
      " |      model is trained with early stopping, then :py:attr:`best_iteration` is used\n",
      " |      automatically. The estimator uses `inplace_predict` by default and falls back to\n",
      " |      using :py:class:`DMatrix` if devices between the data and the estimator don't\n",
      " |      match.\n",
      " |\n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      " |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      " |          probability of each data example being of a given class.\n",
      " |\n",
      " |  set_fit_request(\n",
      " |      self: xgboost.sklearn.XGBClassifier,\n",
      " |      *,\n",
      " |      base_margin: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      eval_set: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      verbose: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$'\n",
      " |  ) -> xgboost.sklearn.XGBClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``fit`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      " |\n",
      " |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      " |\n",
      " |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      " |\n",
      " |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      " |\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      " |\n",
      " |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      " |\n",
      " |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      " |\n",
      " |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_predict_proba_request(\n",
      " |      self: xgboost.sklearn.XGBClassifier,\n",
      " |      *,\n",
      " |      base_margin: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      validate_features: Union[bool, NoneType, str] = '$UNCHANGED$'\n",
      " |  ) -> xgboost.sklearn.XGBClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``predict_proba`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``base_margin`` parameter in ``predict_proba``.\n",
      " |\n",
      " |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``iteration_range`` parameter in ``predict_proba``.\n",
      " |\n",
      " |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``validate_features`` parameter in ``predict_proba``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_predict_request(\n",
      " |      self: xgboost.sklearn.XGBClassifier,\n",
      " |      *,\n",
      " |      base_margin: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      output_margin: Union[bool, NoneType, str] = '$UNCHANGED$',\n",
      " |      validate_features: Union[bool, NoneType, str] = '$UNCHANGED$'\n",
      " |  ) -> xgboost.sklearn.XGBClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``predict`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      " |\n",
      " |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      " |\n",
      " |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      " |\n",
      " |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  set_score_request(\n",
      " |      self: xgboost.sklearn.XGBClassifier,\n",
      " |      *,\n",
      " |      sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$'\n",
      " |  ) -> xgboost.sklearn.XGBClassifier from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      " |      Request metadata passed to the ``score`` method.\n",
      " |\n",
      " |      Note that this method is only relevant if\n",
      " |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      " |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      The options for each parameter are:\n",
      " |\n",
      " |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      " |\n",
      " |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      " |\n",
      " |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      " |\n",
      " |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      " |\n",
      " |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      " |      existing request. This allows you to change the request for some\n",
      " |      parameters and not others.\n",
      " |\n",
      " |      .. versionadded:: 1.3\n",
      " |\n",
      " |      .. note::\n",
      " |          This method is only relevant if this estimator is used as a\n",
      " |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      " |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      " |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          The updated object.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  classes_\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __slotnames__ = []\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |\n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |\n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |\n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |\n",
      " |  __sklearn_is_fitted__(self) -> bool\n",
      " |\n",
      " |  apply(\n",
      " |      self,\n",
      " |      X: Any,\n",
      " |      iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None\n",
      " |  ) -> numpy.ndarray\n",
      " |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      " |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Input features matrix. See :ref:`py-data` for a list of supported types.\n",
      " |\n",
      " |      iteration_range :\n",
      " |          See :py:meth:`predict`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |\n",
      " |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      " |      Return the evaluation results.\n",
      " |\n",
      " |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      " |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      " |      function.\n",
      " |\n",
      " |      The returned evaluation result is a dictionary:\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result\n",
      " |\n",
      " |  get_booster(self) -> xgboost.core.Booster\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |\n",
      " |      This will raise an exception when fit was not called\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |\n",
      " |  get_num_boosting_rounds(self) -> int\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |\n",
      " |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      " |      Get parameters.\n",
      " |\n",
      " |  get_xgb_params(self) -> Dict[str, Any]\n",
      " |      Get xgboost specific parameters.\n",
      " |\n",
      " |  load_model(self, fname: Union[os.PathLike[~AnyStr], bytearray, str]) -> None\n",
      " |      Load the model from a file or a bytearray.\n",
      " |\n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      " |      format. Also, parameters that are not part of the model (like metrics,\n",
      " |      `max_depth`, etc) are not saved, see :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |        model.save_model(\"model.json\")\n",
      " |        model.load_model(\"model.json\")\n",
      " |\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |        model.load_model(\"model.ubj\")\n",
      " |\n",
      " |        # or\n",
      " |        buf = model.save_raw()\n",
      " |        model.load_model(buf)\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |\n",
      " |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      " |      Save the model to a file.\n",
      " |\n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      " |      format. Also, parameters that are not part of the model (like metrics,\n",
      " |      `max_depth`, etc) are not saved, see :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |\n",
      " |      .. code-block:: python\n",
      " |\n",
      " |        model.save_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Output file name\n",
      " |\n",
      " |  set_params(self, **params: Any) -> 'XGBModel'\n",
      " |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      " |      allow unknown kwargs. This allows using the full range of xgboost\n",
      " |      parameters that are not defined as member variables in sklearn grid\n",
      " |      search.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from XGBModel:\n",
      " |\n",
      " |  best_iteration\n",
      " |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      " |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      " |\n",
      " |  best_score\n",
      " |      The best score obtained by early stopping.\n",
      " |\n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |\n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |\n",
      " |          Coefficients are only defined when the linear model is chosen as\n",
      " |          base learner (`booster=gblinear`). It is not defined for other base\n",
      " |          learner types, such as tree learners (`booster=gbtree`).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |\n",
      " |  feature_importances_\n",
      " |      Feature importances property, return depends on `importance_type`\n",
      " |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      " |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      " |      based on the importance type. For instance, if the importance type is\n",
      " |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      " |      trees.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      " |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      " |\n",
      " |  feature_names_in_\n",
      " |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      " |      feature names that are all strings.\n",
      " |\n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |\n",
      " |      For tree-based model, the returned value is the `base_score`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |\n",
      " |  n_features_in_\n",
      " |      Number of features seen during :py:meth:`fit`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |\n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setstate__(self, state)\n",
      " |\n",
      " |  __sklearn_clone__(self)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |\n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |\n",
      " |  __init_subclass__(**kwargs)\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |\n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |\n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xgb.XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "27124ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\":[0.01,0.1,0.3,0.5],\n",
    "    \"max_depth\" : [5,7,9,10],\n",
    "    \"subsample\" : [0.3,0.5,0.7,1],\n",
    "    \"n_estimators\" : [300,500,700,1000]\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f3cf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_model = GridSearchCV(model, parameters,n_jobs=1,scoring = \"f1\",cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "764927ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, feature_weights=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=Non...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [5, 7, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 700, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.3, 0.5, 0.7, 1]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, feature_weights=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=Non...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.3, 0.5],\n",
       "                         &#x27;max_depth&#x27;: [5, 7, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 500, 700, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.3, 0.5, 0.7, 1]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.5, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, feature_weights=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=Non...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
       "             n_jobs=1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
       "                         'max_depth': [5, 7, 9, 10],\n",
       "                         'n_estimators': [300, 500, 700, 1000],\n",
       "                         'subsample': [0.3, 0.5, 0.7, 1]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = gs_model.predict(X_test)\n",
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d6d17830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m121 packages\u001b[0m \u001b[2min 933ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m lightgbm \u001b[2m(1.4MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloaded\u001b[0m\u001b[39m lightgbm\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 386ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightgbm\u001b[0m\u001b[2m==4.6.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bdf81a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4b097bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 815, number of negative: 3964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2878\n",
      "[LightGBM] [Info] Number of data points in the train set: 4779, number of used features: 22\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.170538 -> initscore=-1.581821\n",
      "[LightGBM] [Info] Start training from score -1.581821\n"
     ]
    }
   ],
   "source": [
    "model1 = lgb.LGBMClassifier(random_state=20)\n",
    "model1.fit(X_train,y_train)\n",
    "test_pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9ebebfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8423621278672523"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a9fc48ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9989934 , 0.0010066 ],\n",
       "       [0.92071783, 0.07928217],\n",
       "       [0.46245935, 0.53754065],\n",
       "       ...,\n",
       "       [0.98705352, 0.01294648],\n",
       "       [0.95582662, 0.04417338],\n",
       "       [0.9642382 , 0.0357618 ]], shape=(2049, 2))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
